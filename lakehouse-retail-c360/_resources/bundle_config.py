# Databricks notebook source
# MAGIC %md 
# MAGIC ## Demo bundle configuration
# MAGIC Please ignore / do not delete, only used to prep and bundle the demo

# COMMAND ----------

{
  "name": "lakehouse-retail-c360",
  "category": "retail",
  "title": "Lakehouse - Detect & reduce Churn",
  "description": "Reduce customer churn: Ingest data (DLT), BI/Datawarehousing / Predict churn (ML) / Governance (UC) / Orchestration",
  "bundle": True,
  "tags": [{"dlt": "Delta Live Table"},  {"ds": "Data Science"}, {"uc": "Unity Catalog"}, {"dbsql": "BI/DW/DBSQL"}],
  "notebooks": [
    {
      "path": "_resources/00-prep-data-db-sql", 
      "pre_run": False, 
      "publish_on_website": False, 
      "add_cluster_setup_cell": False,
      "title":  "Dbsql data", 
      "description": "Prep data for dbsql dashboard."
    },
    {
      "path": "_resources/00-setup", 
      "pre_run": False, 
      "publish_on_website": False, 
      "add_cluster_setup_cell": False,
      "title":  "Dbsql data", 
      "description": "Prep data for dbsql dashboard."
    },
    {
      "path": "_resources/00-setup-uc", 
      "pre_run": False, 
      "publish_on_website": False, 
      "add_cluster_setup_cell": False,
      "title":  "Dbsql data", 
      "description": "Prep data for dbsql dashboard."
    },
    {
      "path": "_resources/01-load-data", 
      "pre_run": False, 
      "publish_on_website": False, 
      "add_cluster_setup_cell": False,
      "title":  "Dbsql data", 
      "description": "Prep data for dbsql dashboard."
    },
    {
      "path": "_resources/02-create-churn-tables", 
      "pre_run": False, 
      "publish_on_website": False, 
      "add_cluster_setup_cell": False,
      "title":  "Dbsql data", 
      "description": "Prep data for dbsql dashboard."
    },
    {
      "path": "00-churn-introduction-lakehouse", 
      "pre_run": False,
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Lakehouse - churn introduction", 
      "description": "Start here to explore the Lakehouse."
    },
    {
      "path": "01-Data-ingestion/01.1-DLT-churn-SQL", 
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Ingest data with Delta Live Table", 
      "description": "SQL DLT pipeline to ingest data & build clean tables."
    },
    {
      "path": "01-Data-ingestion/01.2-DLT-churn-Python-UDF", 
      "pre_run": False, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Ingest data with DLT-companion UDF", 
      "description": "Loads ML model as UDF in python."
    },
    {
      "path": "01-Data-ingestion/01.3-DLT-churn-python", 
      "pre_run": False, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Alternative: Ingest data with Delta Live Table", 
      "description": "Python DLT pipeline to ingest data & build clean tables."
    },
    {
      "path": "02-Data-governance/02-UC-data-governance-security-churn", 
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": True,
      "title":  "Governance with Unity Catalog", 
      "description": "Secure your tables, lineage, auditlog..."
    },
    {
      "path": "04-Data-Science-ML/04.1-automl-churn-prediction", 
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": True,
      "title":  "Build churn prediction model (AutoML)", 
      "description": "Leverage Databricks AutoML to create a churn model in a few clicks"
    },
    {
      "path": "04-Data-Science-ML/04.2-automl-generated-notebook",
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": True,
      "title":  "Explore churn Prediction generated model", 
      "description": "Explore the best churn model generated by AutoML and deploy it in production.",
      "parameters": {"shap_enabled": "true"}
    },
    {
      "path": "04-Data-Science-ML/04.3-running-inference", 
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": True,
      "title":  "Infere churn on batch or realtime serverless", 
      "description": "Once your model is deployed, run low latency inferences."
    },
    {
      "path": "01-Data-ingestion/plain-spark-delta-pipeline/01.5-Delta-pipeline-spark-churn", 
      "pre_run": True, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": True,
      "title":  "Alternative: Ingest data with Spark+Delta", 
      "description": "Build a complete ingestion pipeline using spark API (alternative to DLT)"
    },
    {
      "path": "03-BI-data-warehousing/03-BI-Datawarehousing", 
      "pre_run": False, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Datawarehousing & BI / Dashboarding", 
      "description": "Run interactive queries on top of your data"
    },
    {
      "path": "05-Workflow-orchestration/05-Workflow-orchestration-churn", 
      "pre_run": False, 
      "publish_on_website": True, 
      "add_cluster_setup_cell": False,
      "title":  "Orchestrate churn prevention with Workflow", 
      "description": "Leverage Databricks AutoML to create a churn model in a few clicks"
    }
  ],
  "init_job": {
    "settings": {
        "name": "dbdemos_lakehouse_churn_init_{{CURRENT_USER_NAME}}",
        "email_notifications": {
            "no_alert_for_skipped_runs": False
        },
        "timeout_seconds": 0,
        "max_concurrent_runs": 1,
        "tasks": [
            {
                "task_key": "init_data",
                "notebook_task": {
                    "notebook_path": "{{DEMO_FOLDER}}/_resources/00-prep-data-db-sql",
                    "source": "WORKSPACE"
                },
                "job_cluster_key": "Shared_job_cluster",
                "timeout_seconds": 0,
                "email_notifications": {}
            },
            {
                "task_key": "create_feature_and_automl_run",
                "notebook_task": {
                    "notebook_path": "{{DEMO_FOLDER}}/04-Data-Science-ML/04.1-automl-churn-prediction",
                    "source": "WORKSPACE"
                },
                "job_cluster_key": "Shared_job_cluster",
                "timeout_seconds": 0,
                "email_notifications": {},
                "depends_on": [
                      {
                          "task_key": "init_data"
                      }
                  ]
            },
            {
                "task_key": "register_churn_model",
                "notebook_task": {
                    "notebook_path": "{{DEMO_FOLDER}}/04-Data-Science-ML/04.2-automl-generated-notebook",
                    "source": "WORKSPACE"
                },
                "base_parameters": {"shap_enabled": "false"},
                "job_cluster_key": "Shared_job_cluster",
                "timeout_seconds": 0,
                "email_notifications": {},
                "depends_on": [
                      {
                          "task_key": "create_feature_and_automl_run"
                      }
                  ]
            },
            {
                "task_key": "start_dlt_pipeline",
                "pipeline_task": {
                    "pipeline_id": "{{DYNAMIC_DLT_ID_dlt-churn}}",
                    "full_refresh": true
                },
                "timeout_seconds": 0,
                "email_notifications": {},
                "depends_on": [
                    {
                        "task_key": "register_churn_model"
                    }
                ]
            }
        ],
        "job_clusters": [
            {
                "job_cluster_key": "Shared_job_cluster",
                "new_cluster": {
                    "spark_version": "11.3.x-cpu-ml-scala2.12",
                    "spark_conf": {
                        "spark.master": "local[*, 4]",
                        "spark.databricks.cluster.profile": "singleNode"
                    },
                    "custom_tags": {
                        "ResourceClass": "SingleNode"
                    },
                    "spark_env_vars": {
                        "PYSPARK_PYTHON": "/databricks/python3/bin/python3"
                    },
                    "enable_elastic_disk": True,
                    "data_security_mode": "SINGLE_USER",
                    "runtime_engine": "STANDARD",
                    "num_workers": 0
                }
            }
        ],
        "format": "MULTI_TASK"
    }
  },
  "cluster": {
      "spark_conf": {
        "spark.master": "local[*]",
        "spark.databricks.cluster.profile": "singleNode"
    },
    "custom_tags": {
        "ResourceClass": "SingleNode"
    },
    "single_user_name": "{{CURRENT_USER}}",
    "data_security_mode": "SINGLE_USER",
    "num_workers": 0
  }, 
  "pipelines": [
    {
      "id": "dlt-churn",
      "run_after_creation": False,
      "definition": {
        "clusters": [
            {
                "label": "default",
                "autoscale": {
                    "min_workers": 1,
                    "max_workers": 2,
                    "mode": "LEGACY"
                }
            }
        ],
        "development": True,
        "continuous": False,
        "channel": "CURRENT",
        "edition": "ADVANCED",
        "photon": False,
        "libraries": [
            {
                "notebook": {
                    "path": "{{DEMO_FOLDER}}/01-Data-ingestion/01.1-DLT-churn-SQL"
                }
            },
            {
                "notebook": {
                    "path": "{{DEMO_FOLDER}}/01-Data-ingestion/01.2-DLT-churn-Python-UDF"
                }
            }
        ],
        "name": "dbdemos_dlt_lakehouse_churn_{{CURRENT_USER_NAME}}",
        "storage": "/demos/dlt/lakehouse_churn/{{CURRENT_USER_NAME}}",
        "target": "dbdemos_lakehouse_churn_{{CURRENT_USER_NAME}}"
      }
    }
  ]
}
